import json

import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

import torch
import torch.nn as nn
from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments
from datasets import Dataset

json_file = './Gift_Cards.jsonl'
df = pd.read_json(json_file, lines=True)
print(df.head())
print(df.columns.values)
df.drop(['title', 'images', 'asin', 'parent_asin', 'user_id','timestamp','helpful_vote','verified_purchase'], axis=1, inplace=True)

print(df.head())
# è¯„åˆ†è½¬æ ‡ç­¾ï¼š1-2åˆ†=è´Ÿé¢(0)ï¼Œ3åˆ†=ä¸­æ€§(1)ï¼Œ4-5åˆ†=æ­£é¢(2)
labels = []
for label in df['rating'].values:
    if label <= 2:
        labels.append(0)
    elif label == 3:
        labels.append(1)
    else:
        labels.append(2)
print(len(labels))
print(labels[:10])
texts = list([text for text in df["text"]])

train_texts, test_texts, train_labels, test_labels = train_test_split(
    texts,
    labels,
    test_size=0.2,
    random_state=42,
    stratify=labels
)

tokenizer = BertTokenizer.from_pretrained('/home/dzl/baDouNLP/week/google-bert/bert-base-uncased')
model = BertForSequenceClassification.from_pretrained('/home/dzl/baDouNLP/week/google-bert/bert-base-uncased',
                                                      num_labels=3)

# å‡è®¾ train_texts æ˜¯ä½ çš„æ–‡æœ¬åˆ—è¡¨
lengths = [len(tokenizer.encode(text)) for text in train_texts]

print("æœ€å¤§é•¿åº¦:", max(lengths))
print("95%åˆ†ä½æ•°:", np.percentile(lengths, 95))
print("å¹³å‡é•¿åº¦:", np.mean(lengths))
print("ä¸­ä½æ•°:", np.median(lengths))

train_encodings = tokenizer(train_texts, truncation=True, padding=True,max_length=128)
test_encodings= tokenizer(test_texts, truncation=True, padding=True,max_length=128)

# å°†ç¼–ç åçš„æ•°æ®å’Œæ ‡ç­¾è½¬æ¢ä¸º Hugging Face `datasets` åº“çš„ Dataset å¯¹è±¡
train_dataset = Dataset.from_dict({
    'input_ids': train_encodings['input_ids'],           # æ–‡æœ¬çš„token ID
    'attention_mask': train_encodings['attention_mask'], # æ³¨æ„åŠ›æ©ç 
    'labels': train_labels                               # å¯¹åº”çš„æ ‡ç­¾
})
test_dataset = Dataset.from_dict({
    'input_ids': test_encodings['input_ids'],
    'attention_mask': test_encodings['attention_mask'],
    'labels': test_labels
})


from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score


def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)

    # åŸºç¡€æŒ‡æ ‡ï¼ˆä¿æŒä¸å˜ï¼‰
    acc = accuracy_score(labels, predictions)
    precision_macro = precision_score(labels, predictions, average='macro')
    recall_macro = recall_score(labels, predictions, average='macro')
    f1_macro = f1_score(labels, predictions, average='macro')
    f1_weighted = f1_score(labels, predictions, average='weighted')

    # è·å–æ¯ä¸ªç±»åˆ«çš„æŒ‡æ ‡ï¼ˆè¿”å›æ•°ç»„ï¼Œé¡ºåºå¯¹åº”ç±»åˆ« 0, 1, 2, ..., num_classes-1ï¼‰
    precisions = precision_score(labels, predictions, average=None, zero_division=0)
    recalls = recall_score(labels, predictions, average=None, zero_division=0)
    f1s = f1_score(labels, predictions, average=None, zero_division=0)

    # è·å–ç±»åˆ«æ•°é‡ï¼ˆå¯é€‰ï¼šç”¨äºå‘½åï¼‰
    num_classes = len(precisions)

    # æ„å»º per-class æŒ‡æ ‡å­—å…¸
    per_class_metrics = {}
    for i in range(num_classes):
        per_class_metrics[f"precision_class_{i}"] = float(precisions[i])
        per_class_metrics[f"recall_class_{i}"] = float(recalls[i])
        per_class_metrics[f"f1_class_{i}"] = float(f1s[i])

    # åˆå¹¶æ‰€æœ‰æŒ‡æ ‡
    return {
        'accuracy': acc,
        'f1_macro': f1_macro,
        'precision_macro': precision_macro,
        'recall_macro': recall_macro,
        'f1_weighted': f1_weighted,
        **per_class_metrics,  # å±•å¼€ per-class æŒ‡æ ‡
    }
from sklearn.utils.class_weight import compute_class_weight
# ----- 1. è®¡ç®—ç±»åˆ«æƒé‡ï¼ˆè§£å†³ä¸å¹³è¡¡ï¼‰ -----
train_labels = np.array(train_dataset["labels"])
num_classes = len(np.unique(train_labels))
class_weights = compute_class_weight(
    class_weight="balanced",
    classes=np.arange(num_classes),
    y=train_labels
)
# class_weights = torch.tensor(class_weights, dtype=torch.float)
# åœ¨è®¡ç®— class_weights åï¼Œå¼ºåˆ¶æå‡ class_1
class_weights = torch.tensor([3.6, 30.0, 0.4])  # class_1 æƒé‡ Ã—2

# ----- 2. è‡ªå®šä¹‰å¸¦æƒé‡çš„ Trainer -----
class WeightedTrainer(Trainer):
    def __init__(self, class_weights=None, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # class_weights åº”ä¸º 1D tensorï¼Œé•¿åº¦ = num_labels
        self.class_weights = class_weights

    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):
        """
        Compute loss with optional class weights.
        Compatible with Transformers >=4.30
        """
        # 1. å‰å‘ä¼ æ’­
        outputs = model(**inputs)
        logits = outputs.get("logits")
        labels = inputs.get("labels")

        # 2. é€‰æ‹©æŸå¤±å‡½æ•°
        if self.class_weights is not None:
            loss_fct = nn.CrossEntropyLoss(weight=self.class_weights.to(logits.device))
        else:
            loss_fct = nn.CrossEntropyLoss()

        # 3. è®¡ç®— loss
        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))

        # 4. è¿”å›æ ¼å¼å¿…é¡»ä¸çˆ¶ç±»ä¸€è‡´
        return (loss, outputs) if return_outputs else loss


# é…ç½®è®­ç»ƒå‚æ•°
training_args = TrainingArguments(
    output_dir='./ClassificationResultsBalanced',              # è®­ç»ƒè¾“å‡ºç›®å½•ï¼Œç”¨äºä¿å­˜æ¨¡å‹å’ŒçŠ¶æ€
    num_train_epochs=8,                  # è®­ç»ƒçš„æ€»è½®æ•°
    per_device_train_batch_size=64,      # è®­ç»ƒæ—¶æ¯ä¸ªè®¾å¤‡ï¼ˆGPU/CPUï¼‰çš„æ‰¹æ¬¡å¤§å°
    per_device_eval_batch_size=64,       # è¯„ä¼°æ—¶æ¯ä¸ªè®¾å¤‡çš„æ‰¹æ¬¡å¤§å°
    warmup_steps=500,                    # å­¦ä¹ ç‡é¢„çƒ­çš„æ­¥æ•°ï¼Œæœ‰åŠ©äºç¨³å®šè®­ç»ƒ
    learning_rate=2e-5,
    weight_decay=0.01,                   # æƒé‡è¡°å‡ï¼Œç”¨äºé˜²æ­¢è¿‡æ‹Ÿåˆ
    logging_dir='./logs',                # æ—¥å¿—å­˜å‚¨ç›®å½•
    logging_steps=20,                   # æ¯éš”100æ­¥è®°å½•ä¸€æ¬¡æ—¥å¿—

    # eval_strategy="epoch",               # æ¯è®­ç»ƒå®Œä¸€ä¸ª epoch è¿›è¡Œä¸€æ¬¡è¯„ä¼°
    # save_strategy="best",               # æ¯è®­ç»ƒå®Œä¸€ä¸ª epoch ä¿å­˜ä¸€æ¬¡æ¨¡å‹
    # load_best_model_at_end=True,         # è®­ç»ƒç»“æŸååŠ è½½æ•ˆæœæœ€å¥½çš„æ¨¡å‹

    save_strategy="epoch",  # æˆ– "steps"ï¼Œä½†éœ€é…åˆ evaluation_strategy
    eval_strategy="epoch",  # æ³¨æ„ï¼šæ–°ç‰ˆæ¨èç”¨ evaluation_strategy
    save_total_limit=2,  # åªä¿ç•™ best 2 ä¸ªæ¨¡å‹ï¼ŒèŠ‚çœç©ºé—´
    load_best_model_at_end=True,
    metric_for_best_model="f1_macro",  # ğŸ‘ˆ å…³é”®ï¼æŒ‡å®šæ ¹æ® f1_macro é€‰ best
    greater_is_better=True,  # f1_macro è¶Šå¤§è¶Šå¥½
    # ğŸ‘‡ğŸ‘‡ğŸ‘‡ å…³é”®ï¼šå¯ç”¨ wandb
    report_to="wandb",  # å¯ç”¨ wandb æŠ¥å‘Š
    run_name="my-classification-run",  # å¯é€‰ï¼šè‡ªå®šä¹‰è¿è¡Œåç§°ï¼ˆåœ¨ wandb çœ‹æ¿æ˜¾ç¤ºï¼‰
    logging_strategy="steps",  # æŒ‰æ­¥è®°å½•æ—¥å¿—ï¼ˆé»˜è®¤ä¹Ÿæ˜¯ stepsï¼‰
)

# å®ä¾‹åŒ– Trainer
# trainer = Trainer(
#     model=model,                         # è¦è®­ç»ƒçš„æ¨¡å‹
#     args=training_args,                  # è®­ç»ƒå‚æ•°
#     train_dataset=train_dataset,         # è®­ç»ƒæ•°æ®é›†
#     eval_dataset=test_dataset,           # è¯„ä¼°æ•°æ®é›†
#     compute_metrics=compute_metrics,     # ç”¨äºè®¡ç®—è¯„ä¼°æŒ‡æ ‡çš„å‡½æ•°
# )
# ----- 5. å®ä¾‹åŒ–è‡ªå®šä¹‰ Trainer -----
trainer = WeightedTrainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
    compute_metrics=compute_metrics,
    class_weights=class_weights,  # âœ… ä¼ å…¥æƒé‡
)
# å¼€å§‹è®­ç»ƒæ¨¡å‹
trainer.train()
# åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæœ€ç»ˆè¯„ä¼°
trainer.evaluate()
trainer.save_model("best")
print("Done")